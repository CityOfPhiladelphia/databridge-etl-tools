name: Build and test docker image only for PRs

on:
  pull_request:
    branches:
      - '**'

concurrency:
  group: testing_environment
  cancel-in-progress: false

jobs:
  build:
    strategy:
      matrix:
        dockerfile_prefix: [311,312,313,airflow]
    name: Build and test
    if: "!contains(github.event.head_commit.message, 'skip ci')"
    runs-on: self-hosted

    steps:
    # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
    # This is a github function? Ref doc: https://github.com/actions/checkout#checkout-a-different-branch
    # IMPORTANT NOTE: pinned to v3 instead of master, because v4 uses node20 and glibc 2.27. Amazon linux 2 atm only supports
    # glibc 2.26. Change notes: https://github.com/marketplace/actions/checkout
    - uses: actions/checkout@v3

  # https://github.com/marketplace/actions/microsoft-teams-deploy-card
  # Using replacement fork for toko-bifrost, context for why: https://github.com/toko-bifrost/ms-teams-deploy-card/issues/33#issuecomment-888466503 
    #- uses: toko-bifrost/ms-teams-deploy-card@master
    # Note: deprecated because of nodejs 12 and seemingly un-updated.
    # commenting out for now.
    #- uses: patrickpaulin/ms-teams-deploy-card@master
    #  if: always()
    #  with:
    #    GITHUB-TOKEN: ${{ github.token }}
    #    WEBHOOK-URI: ${{ secrets.MS_TEAMS_WEBHOOK_URI }}
    #    card-layout-start: compact
    #    show-on-start: true
    #    show-on-exit: true
    #    custom-facts: |
    #      - name: Job Progress
    #        value: Building databridge-etl-tools
    
    # https://github.com/aws-actions/amazon-ecr-login
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@main
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: us-east-1

    # Prune docker system to clear space
    - name: docker system prune
      run: |
         yes | docker system prune

    # Build our docker container and insert our AWS secret keys
    # no-cache so we're sure we're getting all changes (such as geopetl changes)
    # NOTE: right now just build and test python 3.12 for prod deployment, but we have 3.11 and 3.13 Dockerfiles too.
    - name: Build docker container
      run: |
         docker build -t dbtools-${{ matrix.dockerfile_prefix }} \
         --build-arg AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID \
         --build-arg AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY \
         --no-cache \
         -f Dockerfile-${{ matrix.dockerfile_prefix }} .
      env: 
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}

    # Have to do a special entrypoint for the airflow image.
    - name: Postgres pytests
      run: |
        if [ "${{ matrix.dockerfile_prefix }}" == "airflow" ]; then
          docker run --entrypoint python --rm \
            -e DB_USER=$POSTGRES_USER \
            -e DB_HOST=$POSTGRES_HOST \
            -e DB_PASSWORD=$POSTGRES_PASSWORD \
            -e DB_HOST=$POSTGRES_HOST \
            -e DATABASE=$POSTGRES_DB \
            dbtools-${{ matrix.dockerfile_prefix }} \
            ./.local/bin/pytest tests/test_postgres.py \
            -vvv -ra --showlocals --tb=long --disable-warnings
        else
          docker run --rm \
            -e DB_USER=$POSTGRES_USER \
            -e DB_HOST=$POSTGRES_HOST \
            -e DB_PASSWORD=$POSTGRES_PASSWORD \
            -e DB_HOST=$POSTGRES_HOST \
            -e DATABASE=$POSTGRES_DB \
            dbtools-${{ matrix.dockerfile_prefix }} \
            ./.local/bin/pytest tests/test_postgres.py \
            -vvv -ra --showlocals --tb=long --disable-warnings
        fi
      env:
        POSTGRES_USER: ${{ secrets.POSTGRES_USER }}
        POSTGRES_HOST: ${{ secrets.POSTGRES_HOST }}
        POSTGRES_PASSWORD: ${{ secrets.POSTGRES_PASSWORD }}
        POSTGRES_DB: ${{ secrets.POSTGRES_DB }}

    - name: AGO pytests
      run: |
          docker run --entrypoint python --rm \
            -e AGO_USER=$AGO_USER \
            -e AGO_PASSWORD=$AGO_PASSWORD \
             dbtools-${{ matrix.dockerfile_prefix }} \
            ./.local/bin/pytest tests/test_ago.py \
            -s -vvv -ra --showlocals --tb=long --disable-warnings
      env:
        AGO_USER: ${{ secrets.AGO_USER }}
        AGO_PASSWORD: ${{ secrets.AGO_PASSWORD }}

    - name: Carto pytests
      run: |
          docker run --entrypoint python --rm \
            -e CARTO_USER=$CARTO_USER \
            -e CARTO_PASSWORD=$CARTO_PASSWORD \
            dbtools-${{ matrix.dockerfile_prefix }} \
            ./.local/bin/pytest tests/test_carto.py \
            -s -vvv -ra --showlocals --tb=long --disable-warnings
      env:
        CARTO_USER: ${{ secrets.CARTO_USER }}
        CARTO_PASSWORD: ${{ secrets.CARTO_PASSWORD }}

    - name: Sharepoint pytests
      run: |
        docker run --entrypoint python --rm \
          -e GRAPHAPI_APPLICATION_ID=$GRAPHAPI_APPLICATION_ID \
          -e GRAPHAPI_TENANT_ID=$GRAPHAPI_TENANT_ID \
          -e GRAPHAPI_SECRET_VALUE=$GRAPHAPI_SECRET_VALUE \
          dbtools-${{ matrix.dockerfile_prefix }} \
          ./.local/bin/pytest tests/test_sharepoint.py \
          -s -vvv -ra --showlocals --tb=long --disable-warnings
      env: 
        GRAPHAPI_APPLICATION_ID: ${{ secrets.GRAPHAPI_APPLICATION_ID }}
        GRAPHAPI_TENANT_ID: ${{ secrets.GRAPHAPI_TENANT_ID }}
        GRAPHAPI_SECRET_VALUE: ${{ secrets.GRAPHAPI_SECRET_VALUE }}


    # Push to testing repository
    # https://github.com/aws-actions/amazon-ecr-login
    - name: Login to Amazon ECR
      id: login-ecr
      uses: aws-actions/amazon-ecr-login@v1

    - name: Docker Push 312 to ECR
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        ECR_TEST_REPOSITORY_URL: ${{ secrets.ECR_TEST_REPOSITORY_URL }}
      run: |
        docker tag dbtools-312:latest $ECR_TEST_REPOSITORY_URL:latest
        docker push $ECR_TEST_REPOSITORY_URL:latest